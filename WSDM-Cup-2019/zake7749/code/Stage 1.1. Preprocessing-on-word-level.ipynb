{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import gensim\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from iwillwin.trainer.supervised_trainer import KerasModelTrainer\n",
    "from iwillwin.data_utils.data_helpers import DataTransformer, DataLoader\n",
    "from iwillwin.config import dataset_config\n",
    "from iwillwin.data_utils.feature_engineering import FeatureCreator\n",
    "from simhash import Simhash\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the texts and drop the duplicate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\zake7\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.534 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "\n",
    "spn_train_df = data_loader.load_dataset(dataset_config.DATASET_TRAIN_PATH, names=None)\n",
    "test_df = data_loader.load_dataset(dataset_config.DATASET_TEST_PATH, names=None)\n",
    "\n",
    "train_df = spn_train_df\n",
    "train_df = train_df.drop_duplicates()\n",
    "\n",
    "def preprocessing(text, clean_wiki_tokens=True, drop_image=True):\n",
    "    if type(text) == float:\n",
    "        return 'error'\n",
    "    \n",
    "    words = [w for w in jieba.cut(text)]\n",
    "    text = \" \".join(words)    \n",
    "    text = re.sub(r\"\\<i\\>\", \"\", text)\n",
    "    text = re.sub(r\"|\", \"\", text)\n",
    "    text = re.sub(r\";\", \"\", text)\n",
    "    text = re.sub(r\"，\", \"'\", text)\n",
    "    text = re.sub(r\"！ \", \"'\", text)\n",
    "    text = re.sub(r\"!\", \"\", text)\n",
    "    text = re.sub(r\"¿\", \"\", text)\n",
    "    text = re.sub(r\",\", \"\", text)\n",
    "    text = re.sub(r\"–\", \"\", text)\n",
    "    text = re.sub(r\"−\", \"\", text)\n",
    "    text = re.sub(r\"\\.\", \"\", text)\n",
    "    text = re.sub(r\"!\", \"\", text)\n",
    "    text = re.sub(r\"\\/\", \"\", text)\n",
    "    text = re.sub(r\"_\", \"\", text)\n",
    "    text = re.sub(r\"\\?\", \"\", text)\n",
    "    text = re.sub(r\"？\", \"\", text)\n",
    "    text = re.sub(r\"\\^\", \"\", text)\n",
    "    text = re.sub(r\"\\+\", \"\", text)\n",
    "    text = re.sub(r\"\\-\", \"\", text)\n",
    "    text = re.sub(r\"\\=\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"'\", \"\", text)\n",
    "    return text\n",
    "\n",
    "dfs = [train_df, test_df]\n",
    "\n",
    "train_df['spn_1'] = train_df['title1_zh']\n",
    "train_df['spn_2'] = train_df['title2_zh']\n",
    "\n",
    "test_df['spn_1'] = test_df['title1_zh']\n",
    "test_df['spn_2'] = test_df['title2_zh']\n",
    "\n",
    "for df in [train_df, test_df,]:\n",
    "    df['raw_spn_1'] = df['spn_1'].values\n",
    "    df['raw_spn_2'] = df['spn_2'].values\n",
    "\n",
    "for df in dfs:\n",
    "    df['spn_1'] = df['spn_1'].apply(lambda v: preprocessing(v))\n",
    "    df['spn_2'] = df['spn_2'].apply(lambda v: preprocessing(v))\n",
    "\n",
    "train_df.to_csv(dataset_config.PROCESSED_WORDS_TRAIN_SET, index=False, encoding='utf-8')\n",
    "test_df.to_csv(dataset_config.PROCESSED_WORDS_TEST_SET, index=False, encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 10000\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "OUT_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_on = 'RAW'\n",
    "\n",
    "train_path = dataset_config.PROCESSED_WORDS_TRAIN_SET\n",
    "test_path = dataset_config.PROCESSED_WORDS_TEST_SET\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "data_loader = DataLoader()\n",
    "dfs = [train_df, test_df]\n",
    "\n",
    "if processed_on == 'RAW':\n",
    "    train_output_path = dataset_config.ENGINEERED_WORDS_TRAIN_SET\n",
    "    test_output_path = dataset_config.ENGINEERED_WORDS_TEST_SET\n",
    "    \n",
    "def split(v):\n",
    "    v = str(v)\n",
    "    return v.split()\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['splited_spn_1'] = df['spn_1'].apply(lambda v: v.split())\n",
    "    df['splited_spn_2'] = df['spn_2'].apply(lambda v: v.split())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "      <th>spn_1</th>\n",
       "      <th>spn_2</th>\n",
       "      <th>raw_spn_1</th>\n",
       "      <th>raw_spn_2</th>\n",
       "      <th>splited_spn_1</th>\n",
       "      <th>splited_spn_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2017 养老保险 又 新增 两项  农村 老人 人人 可 申领  你 领到 了 吗</td>\n",
       "      <td>警方 辟谣 “ 鸟巢 大会 每人 领 5 万 ”   仍 有 老人 坚持 进京</td>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>[2017, 养老保险, 又, 新增, 两项, 农村, 老人, 人人, 可, 申领, 你, ...</td>\n",
       "      <td>[警方, 辟谣, “, 鸟巢, 大会, 每人, 领, 5, 万, ”, 仍, 有, 老人, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>\" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...</td>\n",
       "      <td>深圳 GDP 首超 香港  深圳 统计局 辟谣 ： 只是 差距 在 缩小</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>[\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...</td>\n",
       "      <td>[深圳, GDP, 首超, 香港, 深圳, 统计局, 辟谣, ：, 只是, 差距, 在, 缩小]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>\" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...</td>\n",
       "      <td>GDP 首超 香港  深圳 澄清 ： 还 差 一点点 … …</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>[\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...</td>\n",
       "      <td>[GDP, 首超, 香港, 深圳, 澄清, ：, 还, 差, 一点点, …, …]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year? She...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>\" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...</td>\n",
       "      <td>去年 深圳 GDP 首超 香港  深圳 统计局 辟谣 ： 还 差 611 亿</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>[\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...</td>\n",
       "      <td>[去年, 深圳, GDP, 首超, 香港, 深圳, 统计局, 辟谣, ：, 还, 差, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</td>\n",
       "      <td>吃了30年食用油才知道，一片大蒜轻松鉴别地沟油</td>\n",
       "      <td>\"How to discriminate oil from gutter oil by me...</td>\n",
       "      <td>It took 30 years of cooking oil to know that o...</td>\n",
       "      <td>agreed</td>\n",
       "      <td>\" 用 大蒜 鉴别 地沟油 的 方法  怎么 鉴别 地沟油</td>\n",
       "      <td>吃 了 30 年 食用油 才 知道  一片 大蒜 轻松 鉴别 地沟油</td>\n",
       "      <td>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</td>\n",
       "      <td>吃了30年食用油才知道，一片大蒜轻松鉴别地沟油</td>\n",
       "      <td>[\", 用, 大蒜, 鉴别, 地沟油, 的, 方法, 怎么, 鉴别, 地沟油]</td>\n",
       "      <td>[吃, 了, 30, 年, 食用油, 才, 知道, 一片, 大蒜, 轻松, 鉴别, 地沟油]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                          title1_zh  \\\n",
       "0   0     0     1      2017养老保险又新增两项，农村老人人人可申领，你领到了吗   \n",
       "1   3     2     3  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "2   1     2     4  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "3   2     2     5  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "4   9     6     7               \"用大蒜鉴别地沟油的方法,怎么鉴别地沟油   \n",
       "\n",
       "                    title2_zh  \\\n",
       "0    警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京   \n",
       "1   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "2        GDP首超香港？深圳澄清：还差一点点……   \n",
       "3  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿   \n",
       "4     吃了30年食用油才知道，一片大蒜轻松鉴别地沟油   \n",
       "\n",
       "                                           title1_en  \\\n",
       "0  There are two new old-age insurance benefits f...   \n",
       "1  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4  \"How to discriminate oil from gutter oil by me...   \n",
       "\n",
       "                                           title2_en      label  \\\n",
       "0  Police disprove \"bird's nest congress each per...  unrelated   \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated   \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated   \n",
       "3  Shenzhen's GDP topped Hong Kong last year? She...  unrelated   \n",
       "4  It took 30 years of cooking oil to know that o...     agreed   \n",
       "\n",
       "                                               spn_1  \\\n",
       "0         2017 养老保险 又 新增 两项  农村 老人 人人 可 申领  你 领到 了 吗   \n",
       "1  \" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...   \n",
       "2  \" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...   \n",
       "3  \" 你 不来 深圳  早晚 你 儿子 也 要 来 \"  不出 10 年 深圳 人均 GDP ...   \n",
       "4                      \" 用 大蒜 鉴别 地沟油 的 方法  怎么 鉴别 地沟油   \n",
       "\n",
       "                                     spn_2                          raw_spn_1  \\\n",
       "0  警方 辟谣 “ 鸟巢 大会 每人 领 5 万 ”   仍 有 老人 坚持 进京      2017养老保险又新增两项，农村老人人人可申领，你领到了吗   \n",
       "1     深圳 GDP 首超 香港  深圳 统计局 辟谣 ： 只是 差距 在 缩小  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "2           GDP 首超 香港  深圳 澄清 ： 还 差 一点点 … …  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "3   去年 深圳 GDP 首超 香港  深圳 统计局 辟谣 ： 还 差 611 亿  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "4       吃 了 30 年 食用油 才 知道  一片 大蒜 轻松 鉴别 地沟油               \"用大蒜鉴别地沟油的方法,怎么鉴别地沟油   \n",
       "\n",
       "                    raw_spn_2  \\\n",
       "0    警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京   \n",
       "1   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "2        GDP首超香港？深圳澄清：还差一点点……   \n",
       "3  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿   \n",
       "4     吃了30年食用油才知道，一片大蒜轻松鉴别地沟油   \n",
       "\n",
       "                                       splited_spn_1  \\\n",
       "0  [2017, 养老保险, 又, 新增, 两项, 农村, 老人, 人人, 可, 申领, 你, ...   \n",
       "1  [\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...   \n",
       "2  [\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...   \n",
       "3  [\", 你, 不来, 深圳, 早晚, 你, 儿子, 也, 要, 来, \", 不出, 10, ...   \n",
       "4            [\", 用, 大蒜, 鉴别, 地沟油, 的, 方法, 怎么, 鉴别, 地沟油]   \n",
       "\n",
       "                                       splited_spn_2  \n",
       "0  [警方, 辟谣, “, 鸟巢, 大会, 每人, 领, 5, 万, ”, 仍, 有, 老人, ...  \n",
       "1   [深圳, GDP, 首超, 香港, 深圳, 统计局, 辟谣, ：, 只是, 差距, 在, 缩小]  \n",
       "2          [GDP, 首超, 香港, 深圳, 澄清, ：, 还, 差, 一点点, …, …]  \n",
       "3  [去年, 深圳, GDP, 首超, 香港, 深圳, 统计局, 辟谣, ：, 还, 差, 61...  \n",
       "4     [吃, 了, 30, 年, 食用油, 才, 知道, 一片, 大蒜, 轻松, 鉴别, 地沟油]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>spn_1</th>\n",
       "      <th>spn_2</th>\n",
       "      <th>raw_spn_1</th>\n",
       "      <th>raw_spn_2</th>\n",
       "      <th>splited_spn_1</th>\n",
       "      <th>splited_spn_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "      <td>萨拉 赫 人气 爆棚  埃及 总统大选 未 参选 获 百万 选票   现任 总统 压力 山 大</td>\n",
       "      <td>辟谣 里昂 官方 否认 费 基尔 加盟 利物浦  难道 是 价格 没 谈拢</td>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>[萨拉, 赫, 人气, 爆棚, 埃及, 总统大选, 未, 参选, 获, 百万, 选票, 现任...</td>\n",
       "      <td>[辟谣, 里昂, 官方, 否认, 费, 基尔, 加盟, 利物浦, 难道, 是, 价格, 没,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "      <td>萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思</td>\n",
       "      <td>10 大 最 让 美国 人 相信 的 荒诞 谣言  如 蜥蜴人 掌控 着 美国</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]</td>\n",
       "      <td>[10, 大, 最, 让, 美国, 人, 相信, 的, 荒诞, 谣言, 如, 蜥蜴人, 掌控...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>萨达姆 此项 计划 没有 此国 破坏 的话  美国 还会 对 伊拉克 发动战争 吗</td>\n",
       "      <td>萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思</td>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>[萨达姆, 此项, 计划, 没有, 此国, 破坏, 的话, 美国, 还会, 对, 伊拉克, ...</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The hanging Saddam is a surrogate? This man's ...</td>\n",
       "      <td>萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思</td>\n",
       "      <td>被 绞刑 处死 的 萨达姆 是 替身  他 的 此 男人 举动 击破 替身 谣言 ！</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]</td>\n",
       "      <td>[被, 绞刑, 处死, 的, 萨达姆, 是, 替身, 他, 的, 此, 男人, 举动, 击破...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>Chinese loquat loquat plaster in America? Pure...</td>\n",
       "      <td>萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思</td>\n",
       "      <td>中国 川贝 枇杷膏 在 美国 受到 热 捧  纯属 谣言 ！</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]</td>\n",
       "      <td>[中国, 川贝, 枇杷膏, 在, 美国, 受到, 热, 捧, 纯属, 谣言, ！]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                        title1_zh  \\\n",
       "0  321187  167562   59521  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大   \n",
       "1  321190  167564   91315              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "2  321189  167563  167564    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗   \n",
       "3  321193  167564  160994              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "4  321191  167564   15084              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "\n",
       "                     title2_zh  \\\n",
       "0  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                           title1_en  \\\n",
       "0  egypt 's presidential election failed to win m...   \n",
       "1  A message from Saddam Hussein after he was cap...   \n",
       "2  Will the United States wage war on Iraq withou...   \n",
       "3  A message from Saddam Hussein after he was cap...   \n",
       "4  A message from Saddam Hussein after he was cap...   \n",
       "\n",
       "                                           title2_en  \\\n",
       "0  Lyon! Lyon officials have denied that Felipe F...   \n",
       "1  The Top 10 Americans believe that the Lizard M...   \n",
       "2  A message from Saddam Hussein after he was cap...   \n",
       "3  The hanging Saddam is a surrogate? This man's ...   \n",
       "4  Chinese loquat loquat plaster in America? Pure...   \n",
       "\n",
       "                                             spn_1  \\\n",
       "0  萨拉 赫 人气 爆棚  埃及 总统大选 未 参选 获 百万 选票   现任 总统 压力 山 大   \n",
       "1                      萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思   \n",
       "2        萨达姆 此项 计划 没有 此国 破坏 的话  美国 还会 对 伊拉克 发动战争 吗   \n",
       "3                      萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思   \n",
       "4                      萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思   \n",
       "\n",
       "                                        spn_2  \\\n",
       "0      辟谣 里昂 官方 否认 费 基尔 加盟 利物浦  难道 是 价格 没 谈拢    \n",
       "1     10 大 最 让 美国 人 相信 的 荒诞 谣言  如 蜥蜴人 掌控 着 美国   \n",
       "2                 萨达姆 被捕 后 告诫 美国 的 一句 话  发人深思   \n",
       "3  被 绞刑 处死 的 萨达姆 是 替身  他 的 此 男人 举动 击破 替身 谣言 ！   \n",
       "4              中国 川贝 枇杷膏 在 美国 受到 热 捧  纯属 谣言 ！   \n",
       "\n",
       "                         raw_spn_1                    raw_spn_2  \\\n",
       "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                       splited_spn_1  \\\n",
       "0  [萨拉, 赫, 人气, 爆棚, 埃及, 总统大选, 未, 参选, 获, 百万, 选票, 现任...   \n",
       "1               [萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]   \n",
       "2  [萨达姆, 此项, 计划, 没有, 此国, 破坏, 的话, 美国, 还会, 对, 伊拉克, ...   \n",
       "3               [萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]   \n",
       "4               [萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]   \n",
       "\n",
       "                                       splited_spn_2  \n",
       "0  [辟谣, 里昂, 官方, 否认, 费, 基尔, 加盟, 利物浦, 难道, 是, 价格, 没,...  \n",
       "1  [10, 大, 最, 让, 美国, 人, 相信, 的, 荒诞, 谣言, 如, 蜥蜴人, 掌控...  \n",
       "2               [萨达姆, 被捕, 后, 告诫, 美国, 的, 一句, 话, 发人深思]  \n",
       "3  [被, 绞刑, 处死, 的, 萨达姆, 是, 替身, 他, 的, 此, 男人, 举动, 击破...  \n",
       "4          [中国, 川贝, 枇杷膏, 在, 美国, 受到, 热, 捧, 纯属, 谣言, ！]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words in the dictionary = 84834\n",
      "[FE] create the frequency features\n",
      "[FE] creating the IR features\n",
      "[FE] creating the weighted distance features\n",
      "[FE] creating the length features\n",
      "[FE] creating the weight features\n",
      "[FE] creating the distance features\n",
      "[FE] cosine_sim sample= \n",
      " [0.06900655593423542, 0.31448545101657555]\n",
      "[FE] manhattan_dis sample = \n",
      " [27.0, 24.0]\n",
      "[FE] eucledian_dis sample = \n",
      " [5.196152422706632, 5.291502622129181]\n",
      "[FE] jaccard_dis sample = \n",
      " [0.03571428571428571, 0]\n",
      "[FE] minkowsk_dis sample = \n",
      " [5.196152422706632, 5.291502622129181]\n",
      "[FE] creating the fuzzy features\n",
      "[FE] creating the topic word features\n",
      "[FE] TODO! Create the graph features\n",
      "[FE] create the frequency features\n",
      "[FE] creating the IR features\n",
      "[FE] creating the weighted distance features\n",
      "[FE] creating the length features\n",
      "[FE] creating the weight features\n",
      "[FE] creating the distance features\n",
      "[FE] cosine_sim sample= \n",
      " [0.0, 0.24253562503633294]\n",
      "[FE] manhattan_dis sample = \n",
      " [29.0, 20.0]\n",
      "[FE] eucledian_dis sample = \n",
      " [5.385164807134504, 4.47213595499958]\n",
      "[FE] jaccard_dis sample = \n",
      " [0.0, 0]\n",
      "[FE] minkowsk_dis sample = \n",
      " [5.385164807134504, 4.47213595499958]\n",
      "[FE] creating the fuzzy features\n",
      "[FE] creating the topic word features\n",
      "[FE] TODO! Create the graph features\n",
      "[FE] Feature engineered. With features ['id' 'tid1' 'tid2' 'title1_zh' 'title2_zh' 'title1_en' 'title2_en'\n",
      " 'spn_1' 'spn_2' 'raw_spn_1' 'raw_spn_2' 'splited_spn_1' 'splited_spn_2'\n",
      " 'bm25_q1_to_q2' 'bm25_q2_to_q1' 'weighted_cosine_sim' 'len_word_max'\n",
      " 'len_word_min' 'len_char_max' 'len_char_min' 'len_word_q1' 'len_word_q2'\n",
      " 'len_char_q1' 'len_char_q2' 'word_length_diff' 'char_length_diff'\n",
      " 'len_avg_word_1' 'len_avg_word_2' 'avg_word_diff'\n",
      " 'len_diff_remove_stopwords' 'word_shares' 'word_match' 'tfidf_word_match'\n",
      " 'diff_tfidf_word_match' 'shared_count' 'bigram_corr' 'trigram_corr'\n",
      " 'word_match_no_stopwords' 'unique_word_ratio' 'cosine_sim'\n",
      " 'manhattan_dis' 'eucledian_dis' 'jaccard_dis' 'minkowsk_dis'\n",
      " 'fuzzy_ratio' 'fuzzy_set_ratio' 'fuzzy_partial_ratio'\n",
      " 'fuzzy_token_sort_ratio' 'fuzzy_qratio' 'fuzzy_WRatio'\n",
      " 'longest_substr_ratio' 'q1_cómo' 'q2_cómo' 'cómo_both' 'q1_qué' 'q2_qué'\n",
      " 'qué_both']\n",
      "Wall time: 1h 25min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_creator = FeatureCreator(train_df, test_df, data_loader, normalization=False)\n",
    "train_df, test_df = feature_creator.create_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build sim_hash\n",
      "trainset has processed.\n",
      "Build sim_hash\n",
      "testset has processed.\n",
      "Wall time: 1h 7min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def create_hash_features(df):\n",
    "\n",
    "    def get_word_ngrams(sequence, n=3):\n",
    "        return [' '.join(ngram) for ngram in ngrams(sequence, n)]\n",
    "\n",
    "    def get_character_ngrams(sequence, n=3):\n",
    "        sequence = ' '.join(sequence)\n",
    "        return [sequence[i:i+n] for i in range(len(sequence)-n+1)]\n",
    "\n",
    "    def calculate_simhash_distance(sequence1, sequence2):\n",
    "        return Simhash(sequence1).distance(Simhash(sequence2))\n",
    "\n",
    "    def calculate_all_simhash(row):\n",
    "        q1, q2 = row['splited_spn_1'], row['splited_spn_2']\n",
    "        simhash_distance = calculate_simhash_distance(q1, q2)\n",
    "\n",
    "        q1, q2 = get_word_ngrams(q1, 2), get_word_ngrams(q2, 2)\n",
    "        simhash_distance_2gram = calculate_simhash_distance(q1, q2)\n",
    "\n",
    "        q1, q2 = get_word_ngrams(q1, 3), get_word_ngrams(q2, 3)\n",
    "        simhash_distance_3gram = calculate_simhash_distance(q1, q2)\n",
    "\n",
    "        q1, q2 = get_character_ngrams(q1, 2), get_character_ngrams(q2, 2)\n",
    "        simhash_distance_ch_2gram = calculate_simhash_distance(q1, q2)\n",
    "\n",
    "        q1, q2 = get_character_ngrams(q1, 3), get_character_ngrams(q2, 3)\n",
    "        simhash_distance_ch_3gram = calculate_simhash_distance(q1, q2)\n",
    "\n",
    "        return '{}:{}:{}:{}:{}'.format(simhash_distance, simhash_distance_2gram, simhash_distance_3gram,\n",
    "                                             simhash_distance_ch_2gram, simhash_distance_ch_3gram,)\n",
    "\n",
    "\n",
    "    df['sim_hash'] = df.apply(lambda row: calculate_all_simhash(row), axis=1)\n",
    "    print(\"Build sim_hash\")\n",
    "    df['simhash_distance'] = df['sim_hash'].apply(lambda x: float(x.split(':')[0]))\n",
    "    df['simhash_distance_2gram'] = df['sim_hash'].apply(lambda x: float(x.split(':')[1]))\n",
    "    df['simhash_distance_3gram'] = df['sim_hash'].apply(lambda x: float(x.split(':')[2]))\n",
    "    df['simhash_distance_ch_2gram'] = df['sim_hash'].apply(lambda x: float(x.split(':')[3]))\n",
    "    df['simhash_distance_ch_3gram'] = df['sim_hash'].apply(lambda x: float(x.split(':')[4]))\n",
    "    \n",
    "create_hash_features(train_df)\n",
    "print(\"trainset has processed.\")\n",
    "create_hash_features(test_df)\n",
    "print(\"testset has processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JellyFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "def smith_waterman(a, b, alignment_score=1, gap_cost=1):\n",
    "  # H holds the alignment score at each point, computed incrementally\n",
    "    H = np.zeros((len(a) + 1, len(b) + 1))\n",
    "    for i in range(1, len(a) + 1):\n",
    "        for j in range(1, len(b) + 1):\n",
    "        # The score for substituting the letter a[i-1] for b[j-1]. Generally low\n",
    "        # for mismatch, high for match.\n",
    "            match = H[i-1,j -1] + (alignment_score if a[i-1] == b[j-1] else 0)\n",
    "            # The scores for for introducing extra letters in one of the strings (or\n",
    "            # by symmetry, deleting them from the other).\n",
    "            delete = H[1:i,j].max() - gap_cost if i > 1 else 0\n",
    "            insert = H[i,1:j].max() - gap_cost if j > 1 else 0\n",
    "            H[i, j] = max(match, delete, insert, 0)\n",
    "    # The highest score is the best local alignment.\n",
    "    # For our purposes, we don't actually care _what_ the alignment was, just how\n",
    "    # aligned the two strings were.\n",
    "    return H.max()\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['jellyfish_jaro_winkler_distance'] = df[['spn_1', 'spn_2']].apply(lambda row: jellyfish.jaro_winkler(row['spn_1'], row['spn_2']), axis=1)\n",
    "    df['smith_waterman_distance'] = df[['spn_1', 'spn_2']].apply(lambda row: smith_waterman(row['spn_1'], row['spn_2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>bm25_q1_to_q2</th>\n",
       "      <th>bm25_q2_to_q1</th>\n",
       "      <th>weighted_cosine_sim</th>\n",
       "      <th>len_word_max</th>\n",
       "      <th>len_word_min</th>\n",
       "      <th>len_char_max</th>\n",
       "      <th>len_char_min</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_qué</th>\n",
       "      <th>q2_qué</th>\n",
       "      <th>qué_both</th>\n",
       "      <th>simhash_distance</th>\n",
       "      <th>simhash_distance_2gram</th>\n",
       "      <th>simhash_distance_3gram</th>\n",
       "      <th>simhash_distance_ch_2gram</th>\n",
       "      <th>simhash_distance_ch_3gram</th>\n",
       "      <th>jellyfish_jaro_winkler_distance</th>\n",
       "      <th>smith_waterman_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108226</td>\n",
       "      <td>0.071973</td>\n",
       "      <td>-0.076214</td>\n",
       "      <td>-0.077182</td>\n",
       "      <td>-0.061058</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>-0.040056</td>\n",
       "      <td>-0.009280</td>\n",
       "      <td>-0.067526</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.053861</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.026139</td>\n",
       "      <td>-0.032645</td>\n",
       "      <td>-0.051735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tid1</th>\n",
       "      <td>0.108226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>-0.114171</td>\n",
       "      <td>-0.121506</td>\n",
       "      <td>-0.116647</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>-0.048601</td>\n",
       "      <td>-0.019254</td>\n",
       "      <td>-0.048562</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082436</td>\n",
       "      <td>0.051228</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>-0.048200</td>\n",
       "      <td>-0.066867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tid2</th>\n",
       "      <td>0.071973</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.063952</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.045773</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.062692</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>-0.032828</td>\n",
       "      <td>-0.065964</td>\n",
       "      <td>-0.070893</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.102722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25_q1_to_q2</th>\n",
       "      <td>-0.076214</td>\n",
       "      <td>-0.114171</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973797</td>\n",
       "      <td>0.919055</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.251035</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.213770</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.769901</td>\n",
       "      <td>-0.606508</td>\n",
       "      <td>-0.383226</td>\n",
       "      <td>-0.739795</td>\n",
       "      <td>-0.492305</td>\n",
       "      <td>0.695813</td>\n",
       "      <td>0.665216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25_q2_to_q1</th>\n",
       "      <td>-0.077182</td>\n",
       "      <td>-0.121506</td>\n",
       "      <td>0.063952</td>\n",
       "      <td>0.973797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921253</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.230944</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.194022</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.770268</td>\n",
       "      <td>-0.605321</td>\n",
       "      <td>-0.388996</td>\n",
       "      <td>-0.737343</td>\n",
       "      <td>-0.485394</td>\n",
       "      <td>0.622651</td>\n",
       "      <td>0.628454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_cosine_sim</th>\n",
       "      <td>-0.061058</td>\n",
       "      <td>-0.116647</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>0.919055</td>\n",
       "      <td>0.921253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077305</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>-0.112351</td>\n",
       "      <td>0.030513</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.748751</td>\n",
       "      <td>-0.570895</td>\n",
       "      <td>-0.375503</td>\n",
       "      <td>-0.690306</td>\n",
       "      <td>-0.377853</td>\n",
       "      <td>0.664222</td>\n",
       "      <td>0.524746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_word_max</th>\n",
       "      <td>0.009765</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>-0.077305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577986</td>\n",
       "      <td>0.812562</td>\n",
       "      <td>0.510876</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050664</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>-0.050342</td>\n",
       "      <td>-0.347331</td>\n",
       "      <td>-0.021187</td>\n",
       "      <td>0.440220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_word_min</th>\n",
       "      <td>-0.040056</td>\n",
       "      <td>-0.048601</td>\n",
       "      <td>0.045773</td>\n",
       "      <td>0.251035</td>\n",
       "      <td>0.230944</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.577986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488899</td>\n",
       "      <td>0.908560</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.099133</td>\n",
       "      <td>-0.101633</td>\n",
       "      <td>-0.044995</td>\n",
       "      <td>-0.215782</td>\n",
       "      <td>-0.601265</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.742559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_char_max</th>\n",
       "      <td>-0.009280</td>\n",
       "      <td>-0.019254</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>-0.112351</td>\n",
       "      <td>0.812562</td>\n",
       "      <td>0.488899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538249</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075791</td>\n",
       "      <td>0.045719</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>-0.010078</td>\n",
       "      <td>-0.270490</td>\n",
       "      <td>-0.089846</td>\n",
       "      <td>0.384953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_char_min</th>\n",
       "      <td>-0.067526</td>\n",
       "      <td>-0.048562</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>0.213770</td>\n",
       "      <td>0.194022</td>\n",
       "      <td>0.030513</td>\n",
       "      <td>0.510876</td>\n",
       "      <td>0.908560</td>\n",
       "      <td>0.538249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066824</td>\n",
       "      <td>-0.071919</td>\n",
       "      <td>-0.018999</td>\n",
       "      <td>-0.182653</td>\n",
       "      <td>-0.542706</td>\n",
       "      <td>0.089535</td>\n",
       "      <td>0.710006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_word_q1</th>\n",
       "      <td>-0.008725</td>\n",
       "      <td>-0.045538</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.220294</td>\n",
       "      <td>0.125450</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.605960</td>\n",
       "      <td>0.786711</td>\n",
       "      <td>0.501146</td>\n",
       "      <td>0.713546</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053371</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.013066</td>\n",
       "      <td>-0.151566</td>\n",
       "      <td>-0.465231</td>\n",
       "      <td>0.370597</td>\n",
       "      <td>0.706963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_word_q2</th>\n",
       "      <td>-0.022232</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>0.063871</td>\n",
       "      <td>0.154278</td>\n",
       "      <td>-0.032189</td>\n",
       "      <td>0.759018</td>\n",
       "      <td>0.642940</td>\n",
       "      <td>0.626584</td>\n",
       "      <td>0.573802</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>-0.023068</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>-0.096791</td>\n",
       "      <td>-0.394373</td>\n",
       "      <td>-0.247415</td>\n",
       "      <td>0.361067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_char_q1</th>\n",
       "      <td>-0.038301</td>\n",
       "      <td>-0.050796</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.491033</td>\n",
       "      <td>0.712984</td>\n",
       "      <td>0.576509</td>\n",
       "      <td>0.780124</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027385</td>\n",
       "      <td>-0.031189</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>-0.119239</td>\n",
       "      <td>-0.413905</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.659767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_char_q2</th>\n",
       "      <td>-0.037124</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.044539</td>\n",
       "      <td>0.129363</td>\n",
       "      <td>-0.056234</td>\n",
       "      <td>0.641845</td>\n",
       "      <td>0.573172</td>\n",
       "      <td>0.725160</td>\n",
       "      <td>0.635791</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>-0.006788</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.072526</td>\n",
       "      <td>-0.338306</td>\n",
       "      <td>-0.276839</td>\n",
       "      <td>0.342985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_length_diff</th>\n",
       "      <td>0.056359</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>-0.042084</td>\n",
       "      <td>-0.241054</td>\n",
       "      <td>-0.201742</td>\n",
       "      <td>-0.150714</td>\n",
       "      <td>0.299168</td>\n",
       "      <td>-0.605757</td>\n",
       "      <td>0.220584</td>\n",
       "      <td>-0.564269</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165314</td>\n",
       "      <td>0.137767</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.203230</td>\n",
       "      <td>0.364408</td>\n",
       "      <td>-0.198141</td>\n",
       "      <td>-0.439054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_length_diff</th>\n",
       "      <td>0.069926</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>-0.049952</td>\n",
       "      <td>-0.229608</td>\n",
       "      <td>-0.195715</td>\n",
       "      <td>-0.131371</td>\n",
       "      <td>0.106492</td>\n",
       "      <td>-0.629204</td>\n",
       "      <td>0.235392</td>\n",
       "      <td>-0.692405</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141947</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>0.051372</td>\n",
       "      <td>0.202007</td>\n",
       "      <td>0.394283</td>\n",
       "      <td>-0.180170</td>\n",
       "      <td>-0.489220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_avg_word_1</th>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.126133</td>\n",
       "      <td>0.088650</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.373695</td>\n",
       "      <td>0.397421</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.106599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058966</td>\n",
       "      <td>-0.062815</td>\n",
       "      <td>-0.035043</td>\n",
       "      <td>-0.104124</td>\n",
       "      <td>-0.258090</td>\n",
       "      <td>0.269597</td>\n",
       "      <td>0.302881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_avg_word_2</th>\n",
       "      <td>0.017652</td>\n",
       "      <td>-0.024474</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>0.078224</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.422575</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>0.017850</td>\n",
       "      <td>0.076489</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>-0.024767</td>\n",
       "      <td>-0.011373</td>\n",
       "      <td>-0.071202</td>\n",
       "      <td>-0.238303</td>\n",
       "      <td>-0.055257</td>\n",
       "      <td>0.144022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word_diff</th>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>-0.053495</td>\n",
       "      <td>-0.239703</td>\n",
       "      <td>-0.233301</td>\n",
       "      <td>-0.191998</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>-0.242844</td>\n",
       "      <td>-0.057961</td>\n",
       "      <td>-0.179474</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203572</td>\n",
       "      <td>0.164265</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.194370</td>\n",
       "      <td>0.243940</td>\n",
       "      <td>-0.204115</td>\n",
       "      <td>-0.261471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_diff_remove_stopwords</th>\n",
       "      <td>0.053306</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.247428</td>\n",
       "      <td>-0.209530</td>\n",
       "      <td>-0.159187</td>\n",
       "      <td>0.273630</td>\n",
       "      <td>-0.578373</td>\n",
       "      <td>0.211136</td>\n",
       "      <td>-0.544797</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170153</td>\n",
       "      <td>0.137756</td>\n",
       "      <td>0.062358</td>\n",
       "      <td>0.208447</td>\n",
       "      <td>0.358569</td>\n",
       "      <td>-0.210489</td>\n",
       "      <td>-0.439750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_match</th>\n",
       "      <td>-0.081872</td>\n",
       "      <td>-0.110140</td>\n",
       "      <td>0.084292</td>\n",
       "      <td>0.950745</td>\n",
       "      <td>0.949226</td>\n",
       "      <td>0.945094</td>\n",
       "      <td>-0.069005</td>\n",
       "      <td>0.122679</td>\n",
       "      <td>-0.099020</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.790509</td>\n",
       "      <td>-0.612128</td>\n",
       "      <td>-0.388274</td>\n",
       "      <td>-0.739979</td>\n",
       "      <td>-0.437717</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.581510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <td>-0.063037</td>\n",
       "      <td>-0.111236</td>\n",
       "      <td>0.088693</td>\n",
       "      <td>0.943721</td>\n",
       "      <td>0.939572</td>\n",
       "      <td>0.915477</td>\n",
       "      <td>-0.037837</td>\n",
       "      <td>0.169419</td>\n",
       "      <td>-0.074836</td>\n",
       "      <td>0.133147</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.799811</td>\n",
       "      <td>-0.615294</td>\n",
       "      <td>-0.391246</td>\n",
       "      <td>-0.752542</td>\n",
       "      <td>-0.469348</td>\n",
       "      <td>0.698187</td>\n",
       "      <td>0.611692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_tfidf_word_match</th>\n",
       "      <td>0.075724</td>\n",
       "      <td>-0.034447</td>\n",
       "      <td>-0.061192</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>0.123166</td>\n",
       "      <td>0.167141</td>\n",
       "      <td>-0.052447</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>-0.118161</td>\n",
       "      <td>-0.092585</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142159</td>\n",
       "      <td>-0.016699</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>-0.091649</td>\n",
       "      <td>0.012198</td>\n",
       "      <td>0.044928</td>\n",
       "      <td>0.008353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_count</th>\n",
       "      <td>-0.052855</td>\n",
       "      <td>-0.107769</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>0.925654</td>\n",
       "      <td>0.921650</td>\n",
       "      <td>0.832138</td>\n",
       "      <td>0.208224</td>\n",
       "      <td>0.405420</td>\n",
       "      <td>0.133067</td>\n",
       "      <td>0.342649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.743266</td>\n",
       "      <td>-0.593259</td>\n",
       "      <td>-0.385848</td>\n",
       "      <td>-0.735752</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>0.666940</td>\n",
       "      <td>0.762247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram_corr</th>\n",
       "      <td>-0.078551</td>\n",
       "      <td>-0.068697</td>\n",
       "      <td>0.072538</td>\n",
       "      <td>0.842618</td>\n",
       "      <td>0.843176</td>\n",
       "      <td>0.786167</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.188026</td>\n",
       "      <td>-0.030982</td>\n",
       "      <td>0.144551</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.713108</td>\n",
       "      <td>-0.718577</td>\n",
       "      <td>-0.514313</td>\n",
       "      <td>-0.711171</td>\n",
       "      <td>-0.479988</td>\n",
       "      <td>0.674796</td>\n",
       "      <td>0.571141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigram_corr</th>\n",
       "      <td>-0.040687</td>\n",
       "      <td>-0.052429</td>\n",
       "      <td>0.063580</td>\n",
       "      <td>0.751234</td>\n",
       "      <td>0.754838</td>\n",
       "      <td>0.692045</td>\n",
       "      <td>0.055455</td>\n",
       "      <td>0.205642</td>\n",
       "      <td>-0.002608</td>\n",
       "      <td>0.155694</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.646865</td>\n",
       "      <td>-0.689994</td>\n",
       "      <td>-0.567424</td>\n",
       "      <td>-0.652615</td>\n",
       "      <td>-0.463843</td>\n",
       "      <td>0.643447</td>\n",
       "      <td>0.541985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_match_no_stopwords</th>\n",
       "      <td>-0.052855</td>\n",
       "      <td>-0.107769</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>0.925654</td>\n",
       "      <td>0.921650</td>\n",
       "      <td>0.832138</td>\n",
       "      <td>0.208224</td>\n",
       "      <td>0.405420</td>\n",
       "      <td>0.133067</td>\n",
       "      <td>0.342649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.743266</td>\n",
       "      <td>-0.593259</td>\n",
       "      <td>-0.385848</td>\n",
       "      <td>-0.735752</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>0.666940</td>\n",
       "      <td>0.762247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <td>0.064701</td>\n",
       "      <td>0.106224</td>\n",
       "      <td>-0.081544</td>\n",
       "      <td>-0.921141</td>\n",
       "      <td>-0.914642</td>\n",
       "      <td>-0.877693</td>\n",
       "      <td>-0.021233</td>\n",
       "      <td>-0.191426</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>-0.138225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>0.584407</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.722548</td>\n",
       "      <td>0.432857</td>\n",
       "      <td>-0.654986</td>\n",
       "      <td>-0.589666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_sim</th>\n",
       "      <td>-0.057426</td>\n",
       "      <td>-0.110771</td>\n",
       "      <td>0.084725</td>\n",
       "      <td>0.946255</td>\n",
       "      <td>0.943912</td>\n",
       "      <td>0.918912</td>\n",
       "      <td>-0.038881</td>\n",
       "      <td>0.139920</td>\n",
       "      <td>-0.075763</td>\n",
       "      <td>0.099851</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.811452</td>\n",
       "      <td>-0.606716</td>\n",
       "      <td>-0.381217</td>\n",
       "      <td>-0.748959</td>\n",
       "      <td>-0.444785</td>\n",
       "      <td>0.685572</td>\n",
       "      <td>0.581968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manhattan_dis</th>\n",
       "      <td>0.034944</td>\n",
       "      <td>0.068436</td>\n",
       "      <td>-0.066696</td>\n",
       "      <td>-0.744010</td>\n",
       "      <td>-0.742894</td>\n",
       "      <td>-0.794191</td>\n",
       "      <td>0.490899</td>\n",
       "      <td>0.335959</td>\n",
       "      <td>0.443675</td>\n",
       "      <td>0.326243</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685785</td>\n",
       "      <td>0.526214</td>\n",
       "      <td>0.353194</td>\n",
       "      <td>0.580204</td>\n",
       "      <td>0.114682</td>\n",
       "      <td>-0.568598</td>\n",
       "      <td>-0.183083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eucledian_dis</th>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.068565</td>\n",
       "      <td>-0.067280</td>\n",
       "      <td>-0.750640</td>\n",
       "      <td>-0.747138</td>\n",
       "      <td>-0.795505</td>\n",
       "      <td>0.461077</td>\n",
       "      <td>0.276254</td>\n",
       "      <td>0.417114</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706426</td>\n",
       "      <td>0.563408</td>\n",
       "      <td>0.400179</td>\n",
       "      <td>0.601198</td>\n",
       "      <td>0.173570</td>\n",
       "      <td>-0.603580</td>\n",
       "      <td>-0.222522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_dis</th>\n",
       "      <td>-0.066175</td>\n",
       "      <td>-0.039834</td>\n",
       "      <td>0.083846</td>\n",
       "      <td>0.574232</td>\n",
       "      <td>0.578081</td>\n",
       "      <td>0.590870</td>\n",
       "      <td>-0.158820</td>\n",
       "      <td>0.022566</td>\n",
       "      <td>-0.160619</td>\n",
       "      <td>0.021733</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.524101</td>\n",
       "      <td>-0.455312</td>\n",
       "      <td>-0.341099</td>\n",
       "      <td>-0.482310</td>\n",
       "      <td>-0.310669</td>\n",
       "      <td>0.527106</td>\n",
       "      <td>0.351943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minkowsk_dis</th>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.068565</td>\n",
       "      <td>-0.067280</td>\n",
       "      <td>-0.750640</td>\n",
       "      <td>-0.747138</td>\n",
       "      <td>-0.795505</td>\n",
       "      <td>0.461077</td>\n",
       "      <td>0.276254</td>\n",
       "      <td>0.417114</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706426</td>\n",
       "      <td>0.563408</td>\n",
       "      <td>0.400179</td>\n",
       "      <td>0.601198</td>\n",
       "      <td>0.173570</td>\n",
       "      <td>-0.603580</td>\n",
       "      <td>-0.222522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_ratio</th>\n",
       "      <td>-0.031406</td>\n",
       "      <td>-0.067488</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.754925</td>\n",
       "      <td>0.766554</td>\n",
       "      <td>-0.077170</td>\n",
       "      <td>0.196415</td>\n",
       "      <td>-0.092062</td>\n",
       "      <td>0.180136</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.656271</td>\n",
       "      <td>-0.516784</td>\n",
       "      <td>-0.327823</td>\n",
       "      <td>-0.676337</td>\n",
       "      <td>-0.464068</td>\n",
       "      <td>0.771774</td>\n",
       "      <td>0.690133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_set_ratio</th>\n",
       "      <td>-0.062712</td>\n",
       "      <td>-0.109337</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.863056</td>\n",
       "      <td>0.869234</td>\n",
       "      <td>0.901987</td>\n",
       "      <td>-0.070640</td>\n",
       "      <td>0.063643</td>\n",
       "      <td>-0.091314</td>\n",
       "      <td>0.028954</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.739221</td>\n",
       "      <td>-0.542340</td>\n",
       "      <td>-0.339532</td>\n",
       "      <td>-0.671819</td>\n",
       "      <td>-0.368759</td>\n",
       "      <td>0.658731</td>\n",
       "      <td>0.516180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_partial_ratio</th>\n",
       "      <td>-0.033637</td>\n",
       "      <td>-0.079816</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0.687594</td>\n",
       "      <td>0.711581</td>\n",
       "      <td>0.738820</td>\n",
       "      <td>-0.101767</td>\n",
       "      <td>-0.042962</td>\n",
       "      <td>-0.118809</td>\n",
       "      <td>-0.070280</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.605951</td>\n",
       "      <td>-0.426631</td>\n",
       "      <td>-0.251025</td>\n",
       "      <td>-0.590009</td>\n",
       "      <td>-0.283747</td>\n",
       "      <td>0.493488</td>\n",
       "      <td>0.401680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_token_sort_ratio</th>\n",
       "      <td>-0.078556</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>0.101065</td>\n",
       "      <td>0.893871</td>\n",
       "      <td>0.886427</td>\n",
       "      <td>0.872691</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>0.301065</td>\n",
       "      <td>-0.059626</td>\n",
       "      <td>0.271437</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.739169</td>\n",
       "      <td>-0.575024</td>\n",
       "      <td>-0.368619</td>\n",
       "      <td>-0.735147</td>\n",
       "      <td>-0.541573</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.688953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_qratio</th>\n",
       "      <td>-0.033131</td>\n",
       "      <td>-0.067040</td>\n",
       "      <td>0.098459</td>\n",
       "      <td>0.800862</td>\n",
       "      <td>0.755935</td>\n",
       "      <td>0.768157</td>\n",
       "      <td>-0.076106</td>\n",
       "      <td>0.192205</td>\n",
       "      <td>-0.092596</td>\n",
       "      <td>0.177765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.652651</td>\n",
       "      <td>-0.516461</td>\n",
       "      <td>-0.326564</td>\n",
       "      <td>-0.674660</td>\n",
       "      <td>-0.463786</td>\n",
       "      <td>0.769086</td>\n",
       "      <td>0.687099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy_WRatio</th>\n",
       "      <td>-0.046966</td>\n",
       "      <td>-0.108358</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.483535</td>\n",
       "      <td>0.529375</td>\n",
       "      <td>0.500484</td>\n",
       "      <td>0.034746</td>\n",
       "      <td>0.191799</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.413064</td>\n",
       "      <td>-0.227362</td>\n",
       "      <td>-0.097374</td>\n",
       "      <td>-0.384856</td>\n",
       "      <td>-0.279681</td>\n",
       "      <td>0.171025</td>\n",
       "      <td>0.325880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <td>-0.019743</td>\n",
       "      <td>-0.068635</td>\n",
       "      <td>-0.032686</td>\n",
       "      <td>0.226083</td>\n",
       "      <td>0.294989</td>\n",
       "      <td>0.417416</td>\n",
       "      <td>-0.363747</td>\n",
       "      <td>-0.542412</td>\n",
       "      <td>-0.314742</td>\n",
       "      <td>-0.521012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.288566</td>\n",
       "      <td>-0.144182</td>\n",
       "      <td>-0.095057</td>\n",
       "      <td>-0.177735</td>\n",
       "      <td>0.226726</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>-0.219458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_cómo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_cómo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cómo_both</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_qué</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_qué</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qué_both</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simhash_distance</th>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.082436</td>\n",
       "      <td>-0.062692</td>\n",
       "      <td>-0.769901</td>\n",
       "      <td>-0.770268</td>\n",
       "      <td>-0.748751</td>\n",
       "      <td>0.050664</td>\n",
       "      <td>-0.099133</td>\n",
       "      <td>0.075791</td>\n",
       "      <td>-0.066824</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520607</td>\n",
       "      <td>0.347259</td>\n",
       "      <td>0.637732</td>\n",
       "      <td>0.363416</td>\n",
       "      <td>-0.573698</td>\n",
       "      <td>-0.462483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simhash_distance_2gram</th>\n",
       "      <td>0.053861</td>\n",
       "      <td>0.051228</td>\n",
       "      <td>-0.051823</td>\n",
       "      <td>-0.606508</td>\n",
       "      <td>-0.605321</td>\n",
       "      <td>-0.570895</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>-0.101633</td>\n",
       "      <td>0.045719</td>\n",
       "      <td>-0.071919</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411334</td>\n",
       "      <td>0.504227</td>\n",
       "      <td>0.320924</td>\n",
       "      <td>-0.495019</td>\n",
       "      <td>-0.382584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simhash_distance_3gram</th>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>-0.032828</td>\n",
       "      <td>-0.383226</td>\n",
       "      <td>-0.388996</td>\n",
       "      <td>-0.375503</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>-0.044995</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>-0.018999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347259</td>\n",
       "      <td>0.411334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.352774</td>\n",
       "      <td>0.205703</td>\n",
       "      <td>-0.345705</td>\n",
       "      <td>-0.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simhash_distance_ch_2gram</th>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>-0.065964</td>\n",
       "      <td>-0.739795</td>\n",
       "      <td>-0.737343</td>\n",
       "      <td>-0.690306</td>\n",
       "      <td>-0.050342</td>\n",
       "      <td>-0.215782</td>\n",
       "      <td>-0.010078</td>\n",
       "      <td>-0.182653</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637732</td>\n",
       "      <td>0.504227</td>\n",
       "      <td>0.352774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476016</td>\n",
       "      <td>-0.551203</td>\n",
       "      <td>-0.555032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simhash_distance_ch_3gram</th>\n",
       "      <td>0.026139</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>-0.070893</td>\n",
       "      <td>-0.492305</td>\n",
       "      <td>-0.485394</td>\n",
       "      <td>-0.377853</td>\n",
       "      <td>-0.347331</td>\n",
       "      <td>-0.601265</td>\n",
       "      <td>-0.270490</td>\n",
       "      <td>-0.542706</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363416</td>\n",
       "      <td>0.320924</td>\n",
       "      <td>0.205703</td>\n",
       "      <td>0.476016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.368734</td>\n",
       "      <td>-0.668282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jellyfish_jaro_winkler_distance</th>\n",
       "      <td>-0.032645</td>\n",
       "      <td>-0.048200</td>\n",
       "      <td>0.106472</td>\n",
       "      <td>0.695813</td>\n",
       "      <td>0.622651</td>\n",
       "      <td>0.664222</td>\n",
       "      <td>-0.021187</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>-0.089846</td>\n",
       "      <td>0.089535</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.573698</td>\n",
       "      <td>-0.495019</td>\n",
       "      <td>-0.345705</td>\n",
       "      <td>-0.551203</td>\n",
       "      <td>-0.368734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smith_waterman_distance</th>\n",
       "      <td>-0.051735</td>\n",
       "      <td>-0.066867</td>\n",
       "      <td>0.102722</td>\n",
       "      <td>0.665216</td>\n",
       "      <td>0.628454</td>\n",
       "      <td>0.524746</td>\n",
       "      <td>0.440220</td>\n",
       "      <td>0.742559</td>\n",
       "      <td>0.384953</td>\n",
       "      <td>0.710006</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.462483</td>\n",
       "      <td>-0.382584</td>\n",
       "      <td>-0.233500</td>\n",
       "      <td>-0.555032</td>\n",
       "      <td>-0.668282</td>\n",
       "      <td>0.610006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id      tid1      tid2  bm25_q1_to_q2  \\\n",
       "id                               1.000000  0.108226  0.071973      -0.076214   \n",
       "tid1                             0.108226  1.000000  0.294812      -0.114171   \n",
       "tid2                             0.071973  0.294812  1.000000       0.072492   \n",
       "bm25_q1_to_q2                   -0.076214 -0.114171  0.072492       1.000000   \n",
       "bm25_q2_to_q1                   -0.077182 -0.121506  0.063952       0.973797   \n",
       "weighted_cosine_sim             -0.061058 -0.116647  0.069738       0.919055   \n",
       "len_word_max                     0.009765 -0.022400  0.011731       0.053826   \n",
       "len_word_min                    -0.040056 -0.048601  0.045773       0.251035   \n",
       "len_char_max                    -0.009280 -0.019254 -0.005947       0.019754   \n",
       "len_char_min                    -0.067526 -0.048562  0.038901       0.213770   \n",
       "len_word_q1                     -0.008725 -0.045538  0.023162       0.220294   \n",
       "len_word_q2                     -0.022232 -0.019163  0.030563       0.063871   \n",
       "len_char_q1                     -0.038301 -0.050796  0.014095       0.184041   \n",
       "len_char_q2                     -0.037124 -0.012092  0.021021       0.044539   \n",
       "word_length_diff                 0.056359  0.034988 -0.042084      -0.241054   \n",
       "char_length_diff                 0.069926  0.039518 -0.049952      -0.229608   \n",
       "len_avg_word_1                   0.063291  0.001500  0.016026       0.126133   \n",
       "len_avg_word_2                   0.017652 -0.024474  0.011490       0.037951   \n",
       "avg_word_diff                    0.041138  0.005668 -0.053495      -0.239703   \n",
       "len_diff_remove_stopwords        0.053306  0.042710 -0.032715      -0.247428   \n",
       "word_match                      -0.081872 -0.110140  0.084292       0.950745   \n",
       "tfidf_word_match                -0.063037 -0.111236  0.088693       0.943721   \n",
       "diff_tfidf_word_match            0.075724 -0.034447 -0.061192       0.104588   \n",
       "shared_count                    -0.052855 -0.107769  0.098173       0.925654   \n",
       "bigram_corr                     -0.078551 -0.068697  0.072538       0.842618   \n",
       "trigram_corr                    -0.040687 -0.052429  0.063580       0.751234   \n",
       "word_match_no_stopwords         -0.052855 -0.107769  0.098173       0.925654   \n",
       "unique_word_ratio                0.064701  0.106224 -0.081544      -0.921141   \n",
       "cosine_sim                      -0.057426 -0.110771  0.084725       0.946255   \n",
       "manhattan_dis                    0.034944  0.068436 -0.066696      -0.744010   \n",
       "eucledian_dis                    0.032608  0.068565 -0.067280      -0.750640   \n",
       "jaccard_dis                     -0.066175 -0.039834  0.083846       0.574232   \n",
       "minkowsk_dis                     0.032608  0.068565 -0.067280      -0.750640   \n",
       "fuzzy_ratio                     -0.031406 -0.067488  0.100365       0.800020   \n",
       "fuzzy_set_ratio                 -0.062712 -0.109337  0.081253       0.863056   \n",
       "fuzzy_partial_ratio             -0.033637 -0.079816  0.052860       0.687594   \n",
       "fuzzy_token_sort_ratio          -0.078556 -0.107484  0.101065       0.893871   \n",
       "fuzzy_qratio                    -0.033131 -0.067040  0.098459       0.800862   \n",
       "fuzzy_WRatio                    -0.046966 -0.108358  0.016893       0.483535   \n",
       "longest_substr_ratio            -0.019743 -0.068635 -0.032686       0.226083   \n",
       "q1_cómo                               NaN       NaN       NaN            NaN   \n",
       "q2_cómo                               NaN       NaN       NaN            NaN   \n",
       "cómo_both                             NaN       NaN       NaN            NaN   \n",
       "q1_qué                                NaN       NaN       NaN            NaN   \n",
       "q2_qué                                NaN       NaN       NaN            NaN   \n",
       "qué_both                              NaN       NaN       NaN            NaN   \n",
       "simhash_distance                 0.030228  0.082436 -0.062692      -0.769901   \n",
       "simhash_distance_2gram           0.053861  0.051228 -0.051823      -0.606508   \n",
       "simhash_distance_3gram           0.029927  0.028568 -0.032828      -0.383226   \n",
       "simhash_distance_ch_2gram        0.045483  0.083775 -0.065964      -0.739795   \n",
       "simhash_distance_ch_3gram        0.026139  0.079725 -0.070893      -0.492305   \n",
       "jellyfish_jaro_winkler_distance -0.032645 -0.048200  0.106472       0.695813   \n",
       "smith_waterman_distance         -0.051735 -0.066867  0.102722       0.665216   \n",
       "\n",
       "                                 bm25_q2_to_q1  weighted_cosine_sim  \\\n",
       "id                                   -0.077182            -0.061058   \n",
       "tid1                                 -0.121506            -0.116647   \n",
       "tid2                                  0.063952             0.069738   \n",
       "bm25_q1_to_q2                         0.973797             0.919055   \n",
       "bm25_q2_to_q1                         1.000000             0.921253   \n",
       "weighted_cosine_sim                   0.921253             1.000000   \n",
       "len_word_max                          0.070051            -0.077305   \n",
       "len_word_min                          0.230944             0.064433   \n",
       "len_char_max                          0.032744            -0.112351   \n",
       "len_char_min                          0.194022             0.030513   \n",
       "len_word_q1                           0.125450             0.031509   \n",
       "len_word_q2                           0.154278            -0.032189   \n",
       "len_char_q1                           0.092800             0.001353   \n",
       "len_char_q2                           0.129363            -0.056234   \n",
       "word_length_diff                     -0.201742            -0.150714   \n",
       "char_length_diff                     -0.195715            -0.131371   \n",
       "len_avg_word_1                        0.088650             0.055573   \n",
       "len_avg_word_2                        0.078224             0.016380   \n",
       "avg_word_diff                        -0.233301            -0.191998   \n",
       "len_diff_remove_stopwords            -0.209530            -0.159187   \n",
       "word_match                            0.949226             0.945094   \n",
       "tfidf_word_match                      0.939572             0.915477   \n",
       "diff_tfidf_word_match                 0.123166             0.167141   \n",
       "shared_count                          0.921650             0.832138   \n",
       "bigram_corr                           0.843176             0.786167   \n",
       "trigram_corr                          0.754838             0.692045   \n",
       "word_match_no_stopwords               0.921650             0.832138   \n",
       "unique_word_ratio                    -0.914642            -0.877693   \n",
       "cosine_sim                            0.943912             0.918912   \n",
       "manhattan_dis                        -0.742894            -0.794191   \n",
       "eucledian_dis                        -0.747138            -0.795505   \n",
       "jaccard_dis                           0.578081             0.590870   \n",
       "minkowsk_dis                         -0.747138            -0.795505   \n",
       "fuzzy_ratio                           0.754925             0.766554   \n",
       "fuzzy_set_ratio                       0.869234             0.901987   \n",
       "fuzzy_partial_ratio                   0.711581             0.738820   \n",
       "fuzzy_token_sort_ratio                0.886427             0.872691   \n",
       "fuzzy_qratio                          0.755935             0.768157   \n",
       "fuzzy_WRatio                          0.529375             0.500484   \n",
       "longest_substr_ratio                  0.294989             0.417416   \n",
       "q1_cómo                                    NaN                  NaN   \n",
       "q2_cómo                                    NaN                  NaN   \n",
       "cómo_both                                  NaN                  NaN   \n",
       "q1_qué                                     NaN                  NaN   \n",
       "q2_qué                                     NaN                  NaN   \n",
       "qué_both                                   NaN                  NaN   \n",
       "simhash_distance                     -0.770268            -0.748751   \n",
       "simhash_distance_2gram               -0.605321            -0.570895   \n",
       "simhash_distance_3gram               -0.388996            -0.375503   \n",
       "simhash_distance_ch_2gram            -0.737343            -0.690306   \n",
       "simhash_distance_ch_3gram            -0.485394            -0.377853   \n",
       "jellyfish_jaro_winkler_distance       0.622651             0.664222   \n",
       "smith_waterman_distance               0.628454             0.524746   \n",
       "\n",
       "                                 len_word_max  len_word_min  len_char_max  \\\n",
       "id                                   0.009765     -0.040056     -0.009280   \n",
       "tid1                                -0.022400     -0.048601     -0.019254   \n",
       "tid2                                 0.011731      0.045773     -0.005947   \n",
       "bm25_q1_to_q2                        0.053826      0.251035      0.019754   \n",
       "bm25_q2_to_q1                        0.070051      0.230944      0.032744   \n",
       "weighted_cosine_sim                 -0.077305      0.064433     -0.112351   \n",
       "len_word_max                         1.000000      0.577986      0.812562   \n",
       "len_word_min                         0.577986      1.000000      0.488899   \n",
       "len_char_max                         0.812562      0.488899      1.000000   \n",
       "len_char_min                         0.510876      0.908560      0.538249   \n",
       "len_word_q1                          0.605960      0.786711      0.501146   \n",
       "len_word_q2                          0.759018      0.642940      0.626584   \n",
       "len_char_q1                          0.491033      0.712984      0.576509   \n",
       "len_char_q2                          0.641845      0.573172      0.725160   \n",
       "word_length_diff                     0.299168     -0.605757      0.220584   \n",
       "char_length_diff                     0.106492     -0.629204      0.235392   \n",
       "len_avg_word_1                       0.373695      0.397421      0.009601   \n",
       "len_avg_word_2                       0.422575      0.343810      0.017850   \n",
       "avg_word_diff                        0.042565     -0.242844     -0.057961   \n",
       "len_diff_remove_stopwords            0.273630     -0.578373      0.211136   \n",
       "word_match                          -0.069005      0.122679     -0.099020   \n",
       "tfidf_word_match                    -0.037837      0.169419     -0.074836   \n",
       "diff_tfidf_word_match               -0.052447     -0.052932     -0.118161   \n",
       "shared_count                         0.208224      0.405420      0.133067   \n",
       "bigram_corr                          0.017243      0.188026     -0.030982   \n",
       "trigram_corr                         0.055455      0.205642     -0.002608   \n",
       "word_match_no_stopwords              0.208224      0.405420      0.133067   \n",
       "unique_word_ratio                   -0.021233     -0.191426      0.040193   \n",
       "cosine_sim                          -0.038881      0.139920     -0.075763   \n",
       "manhattan_dis                        0.490899      0.335959      0.443675   \n",
       "eucledian_dis                        0.461077      0.276254      0.417114   \n",
       "jaccard_dis                         -0.158820      0.022566     -0.160619   \n",
       "minkowsk_dis                         0.461077      0.276254      0.417114   \n",
       "fuzzy_ratio                         -0.077170      0.196415     -0.092062   \n",
       "fuzzy_set_ratio                     -0.070640      0.063643     -0.091314   \n",
       "fuzzy_partial_ratio                 -0.101767     -0.042962     -0.118809   \n",
       "fuzzy_token_sort_ratio              -0.017804      0.301065     -0.059626   \n",
       "fuzzy_qratio                        -0.076106      0.192205     -0.092596   \n",
       "fuzzy_WRatio                         0.034746      0.191799      0.017189   \n",
       "longest_substr_ratio                -0.363747     -0.542412     -0.314742   \n",
       "q1_cómo                                   NaN           NaN           NaN   \n",
       "q2_cómo                                   NaN           NaN           NaN   \n",
       "cómo_both                                 NaN           NaN           NaN   \n",
       "q1_qué                                    NaN           NaN           NaN   \n",
       "q2_qué                                    NaN           NaN           NaN   \n",
       "qué_both                                  NaN           NaN           NaN   \n",
       "simhash_distance                     0.050664     -0.099133      0.075791   \n",
       "simhash_distance_2gram               0.019413     -0.101633      0.045719   \n",
       "simhash_distance_3gram               0.018946     -0.044995      0.034415   \n",
       "simhash_distance_ch_2gram           -0.050342     -0.215782     -0.010078   \n",
       "simhash_distance_ch_3gram           -0.347331     -0.601265     -0.270490   \n",
       "jellyfish_jaro_winkler_distance     -0.021187      0.151787     -0.089846   \n",
       "smith_waterman_distance              0.440220      0.742559      0.384953   \n",
       "\n",
       "                                 len_char_min           ...             \\\n",
       "id                                  -0.067526           ...              \n",
       "tid1                                -0.048562           ...              \n",
       "tid2                                 0.038901           ...              \n",
       "bm25_q1_to_q2                        0.213770           ...              \n",
       "bm25_q2_to_q1                        0.194022           ...              \n",
       "weighted_cosine_sim                  0.030513           ...              \n",
       "len_word_max                         0.510876           ...              \n",
       "len_word_min                         0.908560           ...              \n",
       "len_char_max                         0.538249           ...              \n",
       "len_char_min                         1.000000           ...              \n",
       "len_word_q1                          0.713546           ...              \n",
       "len_word_q2                          0.573802           ...              \n",
       "len_char_q1                          0.780124           ...              \n",
       "len_char_q2                          0.635791           ...              \n",
       "word_length_diff                    -0.564269           ...              \n",
       "char_length_diff                    -0.692405           ...              \n",
       "len_avg_word_1                       0.106599           ...              \n",
       "len_avg_word_2                       0.076489           ...              \n",
       "avg_word_diff                       -0.179474           ...              \n",
       "len_diff_remove_stopwords           -0.544797           ...              \n",
       "word_match                           0.094944           ...              \n",
       "tfidf_word_match                     0.133147           ...              \n",
       "diff_tfidf_word_match               -0.092585           ...              \n",
       "shared_count                         0.342649           ...              \n",
       "bigram_corr                          0.144551           ...              \n",
       "trigram_corr                         0.155694           ...              \n",
       "word_match_no_stopwords              0.342649           ...              \n",
       "unique_word_ratio                   -0.138225           ...              \n",
       "cosine_sim                           0.099851           ...              \n",
       "manhattan_dis                        0.326243           ...              \n",
       "eucledian_dis                        0.269545           ...              \n",
       "jaccard_dis                          0.021733           ...              \n",
       "minkowsk_dis                         0.269545           ...              \n",
       "fuzzy_ratio                          0.180136           ...              \n",
       "fuzzy_set_ratio                      0.028954           ...              \n",
       "fuzzy_partial_ratio                 -0.070280           ...              \n",
       "fuzzy_token_sort_ratio               0.271437           ...              \n",
       "fuzzy_qratio                         0.177765           ...              \n",
       "fuzzy_WRatio                         0.192844           ...              \n",
       "longest_substr_ratio                -0.521012           ...              \n",
       "q1_cómo                                   NaN           ...              \n",
       "q2_cómo                                   NaN           ...              \n",
       "cómo_both                                 NaN           ...              \n",
       "q1_qué                                    NaN           ...              \n",
       "q2_qué                                    NaN           ...              \n",
       "qué_both                                  NaN           ...              \n",
       "simhash_distance                    -0.066824           ...              \n",
       "simhash_distance_2gram              -0.071919           ...              \n",
       "simhash_distance_3gram              -0.018999           ...              \n",
       "simhash_distance_ch_2gram           -0.182653           ...              \n",
       "simhash_distance_ch_3gram           -0.542706           ...              \n",
       "jellyfish_jaro_winkler_distance      0.089535           ...              \n",
       "smith_waterman_distance              0.710006           ...              \n",
       "\n",
       "                                 q1_qué  q2_qué  qué_both  simhash_distance  \\\n",
       "id                                  NaN     NaN       NaN          0.030228   \n",
       "tid1                                NaN     NaN       NaN          0.082436   \n",
       "tid2                                NaN     NaN       NaN         -0.062692   \n",
       "bm25_q1_to_q2                       NaN     NaN       NaN         -0.769901   \n",
       "bm25_q2_to_q1                       NaN     NaN       NaN         -0.770268   \n",
       "weighted_cosine_sim                 NaN     NaN       NaN         -0.748751   \n",
       "len_word_max                        NaN     NaN       NaN          0.050664   \n",
       "len_word_min                        NaN     NaN       NaN         -0.099133   \n",
       "len_char_max                        NaN     NaN       NaN          0.075791   \n",
       "len_char_min                        NaN     NaN       NaN         -0.066824   \n",
       "len_word_q1                         NaN     NaN       NaN         -0.053371   \n",
       "len_word_q2                         NaN     NaN       NaN         -0.001029   \n",
       "len_char_q1                         NaN     NaN       NaN         -0.027385   \n",
       "len_char_q2                         NaN     NaN       NaN          0.017659   \n",
       "word_length_diff                    NaN     NaN       NaN          0.165314   \n",
       "char_length_diff                    NaN     NaN       NaN          0.141947   \n",
       "len_avg_word_1                      NaN     NaN       NaN         -0.058966   \n",
       "len_avg_word_2                      NaN     NaN       NaN         -0.014036   \n",
       "avg_word_diff                       NaN     NaN       NaN          0.203572   \n",
       "len_diff_remove_stopwords           NaN     NaN       NaN          0.170153   \n",
       "word_match                          NaN     NaN       NaN         -0.790509   \n",
       "tfidf_word_match                    NaN     NaN       NaN         -0.799811   \n",
       "diff_tfidf_word_match               NaN     NaN       NaN         -0.142159   \n",
       "shared_count                        NaN     NaN       NaN         -0.743266   \n",
       "bigram_corr                         NaN     NaN       NaN         -0.713108   \n",
       "trigram_corr                        NaN     NaN       NaN         -0.646865   \n",
       "word_match_no_stopwords             NaN     NaN       NaN         -0.743266   \n",
       "unique_word_ratio                   NaN     NaN       NaN          0.764294   \n",
       "cosine_sim                          NaN     NaN       NaN         -0.811452   \n",
       "manhattan_dis                       NaN     NaN       NaN          0.685785   \n",
       "eucledian_dis                       NaN     NaN       NaN          0.706426   \n",
       "jaccard_dis                         NaN     NaN       NaN         -0.524101   \n",
       "minkowsk_dis                        NaN     NaN       NaN          0.706426   \n",
       "fuzzy_ratio                         NaN     NaN       NaN         -0.656271   \n",
       "fuzzy_set_ratio                     NaN     NaN       NaN         -0.739221   \n",
       "fuzzy_partial_ratio                 NaN     NaN       NaN         -0.605951   \n",
       "fuzzy_token_sort_ratio              NaN     NaN       NaN         -0.739169   \n",
       "fuzzy_qratio                        NaN     NaN       NaN         -0.652651   \n",
       "fuzzy_WRatio                        NaN     NaN       NaN         -0.413064   \n",
       "longest_substr_ratio                NaN     NaN       NaN         -0.288566   \n",
       "q1_cómo                             NaN     NaN       NaN               NaN   \n",
       "q2_cómo                             NaN     NaN       NaN               NaN   \n",
       "cómo_both                           NaN     NaN       NaN               NaN   \n",
       "q1_qué                              NaN     NaN       NaN               NaN   \n",
       "q2_qué                              NaN     NaN       NaN               NaN   \n",
       "qué_both                            NaN     NaN       NaN               NaN   \n",
       "simhash_distance                    NaN     NaN       NaN          1.000000   \n",
       "simhash_distance_2gram              NaN     NaN       NaN          0.520607   \n",
       "simhash_distance_3gram              NaN     NaN       NaN          0.347259   \n",
       "simhash_distance_ch_2gram           NaN     NaN       NaN          0.637732   \n",
       "simhash_distance_ch_3gram           NaN     NaN       NaN          0.363416   \n",
       "jellyfish_jaro_winkler_distance     NaN     NaN       NaN         -0.573698   \n",
       "smith_waterman_distance             NaN     NaN       NaN         -0.462483   \n",
       "\n",
       "                                 simhash_distance_2gram  \\\n",
       "id                                             0.053861   \n",
       "tid1                                           0.051228   \n",
       "tid2                                          -0.051823   \n",
       "bm25_q1_to_q2                                 -0.606508   \n",
       "bm25_q2_to_q1                                 -0.605321   \n",
       "weighted_cosine_sim                           -0.570895   \n",
       "len_word_max                                   0.019413   \n",
       "len_word_min                                  -0.101633   \n",
       "len_char_max                                   0.045719   \n",
       "len_char_min                                  -0.071919   \n",
       "len_word_q1                                   -0.059078   \n",
       "len_word_q2                                   -0.023068   \n",
       "len_char_q1                                   -0.031189   \n",
       "len_char_q2                                   -0.006788   \n",
       "word_length_diff                               0.137767   \n",
       "char_length_diff                               0.122077   \n",
       "len_avg_word_1                                -0.062815   \n",
       "len_avg_word_2                                -0.024767   \n",
       "avg_word_diff                                  0.164265   \n",
       "len_diff_remove_stopwords                      0.137756   \n",
       "word_match                                    -0.612128   \n",
       "tfidf_word_match                              -0.615294   \n",
       "diff_tfidf_word_match                         -0.016699   \n",
       "shared_count                                  -0.593259   \n",
       "bigram_corr                                   -0.718577   \n",
       "trigram_corr                                  -0.689994   \n",
       "word_match_no_stopwords                       -0.593259   \n",
       "unique_word_ratio                              0.584407   \n",
       "cosine_sim                                    -0.606716   \n",
       "manhattan_dis                                  0.526214   \n",
       "eucledian_dis                                  0.563408   \n",
       "jaccard_dis                                   -0.455312   \n",
       "minkowsk_dis                                   0.563408   \n",
       "fuzzy_ratio                                   -0.516784   \n",
       "fuzzy_set_ratio                               -0.542340   \n",
       "fuzzy_partial_ratio                           -0.426631   \n",
       "fuzzy_token_sort_ratio                        -0.575024   \n",
       "fuzzy_qratio                                  -0.516461   \n",
       "fuzzy_WRatio                                  -0.227362   \n",
       "longest_substr_ratio                          -0.144182   \n",
       "q1_cómo                                             NaN   \n",
       "q2_cómo                                             NaN   \n",
       "cómo_both                                           NaN   \n",
       "q1_qué                                              NaN   \n",
       "q2_qué                                              NaN   \n",
       "qué_both                                            NaN   \n",
       "simhash_distance                               0.520607   \n",
       "simhash_distance_2gram                         1.000000   \n",
       "simhash_distance_3gram                         0.411334   \n",
       "simhash_distance_ch_2gram                      0.504227   \n",
       "simhash_distance_ch_3gram                      0.320924   \n",
       "jellyfish_jaro_winkler_distance               -0.495019   \n",
       "smith_waterman_distance                       -0.382584   \n",
       "\n",
       "                                 simhash_distance_3gram  \\\n",
       "id                                             0.029927   \n",
       "tid1                                           0.028568   \n",
       "tid2                                          -0.032828   \n",
       "bm25_q1_to_q2                                 -0.383226   \n",
       "bm25_q2_to_q1                                 -0.388996   \n",
       "weighted_cosine_sim                           -0.375503   \n",
       "len_word_max                                   0.018946   \n",
       "len_word_min                                  -0.044995   \n",
       "len_char_max                                   0.034415   \n",
       "len_char_min                                  -0.018999   \n",
       "len_word_q1                                   -0.013066   \n",
       "len_word_q2                                   -0.015152   \n",
       "len_char_q1                                    0.010113   \n",
       "len_char_q2                                   -0.003775   \n",
       "word_length_diff                               0.071086   \n",
       "char_length_diff                               0.051372   \n",
       "len_avg_word_1                                -0.035043   \n",
       "len_avg_word_2                                -0.011373   \n",
       "avg_word_diff                                  0.098439   \n",
       "len_diff_remove_stopwords                      0.062358   \n",
       "word_match                                    -0.388274   \n",
       "tfidf_word_match                              -0.391246   \n",
       "diff_tfidf_word_match                          0.038558   \n",
       "shared_count                                  -0.385848   \n",
       "bigram_corr                                   -0.514313   \n",
       "trigram_corr                                  -0.567424   \n",
       "word_match_no_stopwords                       -0.385848   \n",
       "unique_word_ratio                              0.362012   \n",
       "cosine_sim                                    -0.381217   \n",
       "manhattan_dis                                  0.353194   \n",
       "eucledian_dis                                  0.400179   \n",
       "jaccard_dis                                   -0.341099   \n",
       "minkowsk_dis                                   0.400179   \n",
       "fuzzy_ratio                                   -0.327823   \n",
       "fuzzy_set_ratio                               -0.339532   \n",
       "fuzzy_partial_ratio                           -0.251025   \n",
       "fuzzy_token_sort_ratio                        -0.368619   \n",
       "fuzzy_qratio                                  -0.326564   \n",
       "fuzzy_WRatio                                  -0.097374   \n",
       "longest_substr_ratio                          -0.095057   \n",
       "q1_cómo                                             NaN   \n",
       "q2_cómo                                             NaN   \n",
       "cómo_both                                           NaN   \n",
       "q1_qué                                              NaN   \n",
       "q2_qué                                              NaN   \n",
       "qué_both                                            NaN   \n",
       "simhash_distance                               0.347259   \n",
       "simhash_distance_2gram                         0.411334   \n",
       "simhash_distance_3gram                         1.000000   \n",
       "simhash_distance_ch_2gram                      0.352774   \n",
       "simhash_distance_ch_3gram                      0.205703   \n",
       "jellyfish_jaro_winkler_distance               -0.345705   \n",
       "smith_waterman_distance                       -0.233500   \n",
       "\n",
       "                                 simhash_distance_ch_2gram  \\\n",
       "id                                                0.045483   \n",
       "tid1                                              0.083775   \n",
       "tid2                                             -0.065964   \n",
       "bm25_q1_to_q2                                    -0.739795   \n",
       "bm25_q2_to_q1                                    -0.737343   \n",
       "weighted_cosine_sim                              -0.690306   \n",
       "len_word_max                                     -0.050342   \n",
       "len_word_min                                     -0.215782   \n",
       "len_char_max                                     -0.010078   \n",
       "len_char_min                                     -0.182653   \n",
       "len_word_q1                                      -0.151566   \n",
       "len_word_q2                                      -0.096791   \n",
       "len_char_q1                                      -0.119239   \n",
       "len_char_q2                                      -0.072526   \n",
       "word_length_diff                                  0.203230   \n",
       "char_length_diff                                  0.202007   \n",
       "len_avg_word_1                                   -0.104124   \n",
       "len_avg_word_2                                   -0.071202   \n",
       "avg_word_diff                                     0.194370   \n",
       "len_diff_remove_stopwords                         0.208447   \n",
       "word_match                                       -0.739979   \n",
       "tfidf_word_match                                 -0.752542   \n",
       "diff_tfidf_word_match                            -0.091649   \n",
       "shared_count                                     -0.735752   \n",
       "bigram_corr                                      -0.711171   \n",
       "trigram_corr                                     -0.652615   \n",
       "word_match_no_stopwords                          -0.735752   \n",
       "unique_word_ratio                                 0.722548   \n",
       "cosine_sim                                       -0.748959   \n",
       "manhattan_dis                                     0.580204   \n",
       "eucledian_dis                                     0.601198   \n",
       "jaccard_dis                                      -0.482310   \n",
       "minkowsk_dis                                      0.601198   \n",
       "fuzzy_ratio                                      -0.676337   \n",
       "fuzzy_set_ratio                                  -0.671819   \n",
       "fuzzy_partial_ratio                              -0.590009   \n",
       "fuzzy_token_sort_ratio                           -0.735147   \n",
       "fuzzy_qratio                                     -0.674660   \n",
       "fuzzy_WRatio                                     -0.384856   \n",
       "longest_substr_ratio                             -0.177735   \n",
       "q1_cómo                                                NaN   \n",
       "q2_cómo                                                NaN   \n",
       "cómo_both                                              NaN   \n",
       "q1_qué                                                 NaN   \n",
       "q2_qué                                                 NaN   \n",
       "qué_both                                               NaN   \n",
       "simhash_distance                                  0.637732   \n",
       "simhash_distance_2gram                            0.504227   \n",
       "simhash_distance_3gram                            0.352774   \n",
       "simhash_distance_ch_2gram                         1.000000   \n",
       "simhash_distance_ch_3gram                         0.476016   \n",
       "jellyfish_jaro_winkler_distance                  -0.551203   \n",
       "smith_waterman_distance                          -0.555032   \n",
       "\n",
       "                                 simhash_distance_ch_3gram  \\\n",
       "id                                                0.026139   \n",
       "tid1                                              0.079725   \n",
       "tid2                                             -0.070893   \n",
       "bm25_q1_to_q2                                    -0.492305   \n",
       "bm25_q2_to_q1                                    -0.485394   \n",
       "weighted_cosine_sim                              -0.377853   \n",
       "len_word_max                                     -0.347331   \n",
       "len_word_min                                     -0.601265   \n",
       "len_char_max                                     -0.270490   \n",
       "len_char_min                                     -0.542706   \n",
       "len_word_q1                                      -0.465231   \n",
       "len_word_q2                                      -0.394373   \n",
       "len_char_q1                                      -0.413905   \n",
       "len_char_q2                                      -0.338306   \n",
       "word_length_diff                                  0.364408   \n",
       "char_length_diff                                  0.394283   \n",
       "len_avg_word_1                                   -0.258090   \n",
       "len_avg_word_2                                   -0.238303   \n",
       "avg_word_diff                                     0.243940   \n",
       "len_diff_remove_stopwords                         0.358569   \n",
       "word_match                                       -0.437717   \n",
       "tfidf_word_match                                 -0.469348   \n",
       "diff_tfidf_word_match                             0.012198   \n",
       "shared_count                                     -0.577074   \n",
       "bigram_corr                                      -0.479988   \n",
       "trigram_corr                                     -0.463843   \n",
       "word_match_no_stopwords                          -0.577074   \n",
       "unique_word_ratio                                 0.432857   \n",
       "cosine_sim                                       -0.444785   \n",
       "manhattan_dis                                     0.114682   \n",
       "eucledian_dis                                     0.173570   \n",
       "jaccard_dis                                      -0.310669   \n",
       "minkowsk_dis                                      0.173570   \n",
       "fuzzy_ratio                                      -0.464068   \n",
       "fuzzy_set_ratio                                  -0.368759   \n",
       "fuzzy_partial_ratio                              -0.283747   \n",
       "fuzzy_token_sort_ratio                           -0.541573   \n",
       "fuzzy_qratio                                     -0.463786   \n",
       "fuzzy_WRatio                                     -0.279681   \n",
       "longest_substr_ratio                              0.226726   \n",
       "q1_cómo                                                NaN   \n",
       "q2_cómo                                                NaN   \n",
       "cómo_both                                              NaN   \n",
       "q1_qué                                                 NaN   \n",
       "q2_qué                                                 NaN   \n",
       "qué_both                                               NaN   \n",
       "simhash_distance                                  0.363416   \n",
       "simhash_distance_2gram                            0.320924   \n",
       "simhash_distance_3gram                            0.205703   \n",
       "simhash_distance_ch_2gram                         0.476016   \n",
       "simhash_distance_ch_3gram                         1.000000   \n",
       "jellyfish_jaro_winkler_distance                  -0.368734   \n",
       "smith_waterman_distance                          -0.668282   \n",
       "\n",
       "                                 jellyfish_jaro_winkler_distance  \\\n",
       "id                                                     -0.032645   \n",
       "tid1                                                   -0.048200   \n",
       "tid2                                                    0.106472   \n",
       "bm25_q1_to_q2                                           0.695813   \n",
       "bm25_q2_to_q1                                           0.622651   \n",
       "weighted_cosine_sim                                     0.664222   \n",
       "len_word_max                                           -0.021187   \n",
       "len_word_min                                            0.151787   \n",
       "len_char_max                                           -0.089846   \n",
       "len_char_min                                            0.089535   \n",
       "len_word_q1                                             0.370597   \n",
       "len_word_q2                                            -0.247415   \n",
       "len_char_q1                                             0.287719   \n",
       "len_char_q2                                            -0.276839   \n",
       "word_length_diff                                       -0.198141   \n",
       "char_length_diff                                       -0.180170   \n",
       "len_avg_word_1                                          0.269597   \n",
       "len_avg_word_2                                         -0.055257   \n",
       "avg_word_diff                                          -0.204115   \n",
       "len_diff_remove_stopwords                              -0.210489   \n",
       "word_match                                              0.690159   \n",
       "tfidf_word_match                                        0.698187   \n",
       "diff_tfidf_word_match                                   0.044928   \n",
       "shared_count                                            0.666940   \n",
       "bigram_corr                                             0.674796   \n",
       "trigram_corr                                            0.643447   \n",
       "word_match_no_stopwords                                 0.666940   \n",
       "unique_word_ratio                                      -0.654986   \n",
       "cosine_sim                                              0.685572   \n",
       "manhattan_dis                                          -0.568598   \n",
       "eucledian_dis                                          -0.603580   \n",
       "jaccard_dis                                             0.527106   \n",
       "minkowsk_dis                                           -0.603580   \n",
       "fuzzy_ratio                                             0.771774   \n",
       "fuzzy_set_ratio                                         0.658731   \n",
       "fuzzy_partial_ratio                                     0.493488   \n",
       "fuzzy_token_sort_ratio                                  0.686358   \n",
       "fuzzy_qratio                                            0.769086   \n",
       "fuzzy_WRatio                                            0.171025   \n",
       "longest_substr_ratio                                    0.085675   \n",
       "q1_cómo                                                      NaN   \n",
       "q2_cómo                                                      NaN   \n",
       "cómo_both                                                    NaN   \n",
       "q1_qué                                                       NaN   \n",
       "q2_qué                                                       NaN   \n",
       "qué_both                                                     NaN   \n",
       "simhash_distance                                       -0.573698   \n",
       "simhash_distance_2gram                                 -0.495019   \n",
       "simhash_distance_3gram                                 -0.345705   \n",
       "simhash_distance_ch_2gram                              -0.551203   \n",
       "simhash_distance_ch_3gram                              -0.368734   \n",
       "jellyfish_jaro_winkler_distance                         1.000000   \n",
       "smith_waterman_distance                                 0.610006   \n",
       "\n",
       "                                 smith_waterman_distance  \n",
       "id                                             -0.051735  \n",
       "tid1                                           -0.066867  \n",
       "tid2                                            0.102722  \n",
       "bm25_q1_to_q2                                   0.665216  \n",
       "bm25_q2_to_q1                                   0.628454  \n",
       "weighted_cosine_sim                             0.524746  \n",
       "len_word_max                                    0.440220  \n",
       "len_word_min                                    0.742559  \n",
       "len_char_max                                    0.384953  \n",
       "len_char_min                                    0.710006  \n",
       "len_word_q1                                     0.706963  \n",
       "len_word_q2                                     0.361067  \n",
       "len_char_q1                                     0.659767  \n",
       "len_char_q2                                     0.342985  \n",
       "word_length_diff                               -0.439054  \n",
       "char_length_diff                               -0.489220  \n",
       "len_avg_word_1                                  0.302881  \n",
       "len_avg_word_2                                  0.144022  \n",
       "avg_word_diff                                  -0.261471  \n",
       "len_diff_remove_stopwords                      -0.439750  \n",
       "word_match                                      0.581510  \n",
       "tfidf_word_match                                0.611692  \n",
       "diff_tfidf_word_match                           0.008353  \n",
       "shared_count                                    0.762247  \n",
       "bigram_corr                                     0.571141  \n",
       "trigram_corr                                    0.541985  \n",
       "word_match_no_stopwords                         0.762247  \n",
       "unique_word_ratio                              -0.589666  \n",
       "cosine_sim                                      0.581968  \n",
       "manhattan_dis                                  -0.183083  \n",
       "eucledian_dis                                  -0.222522  \n",
       "jaccard_dis                                     0.351943  \n",
       "minkowsk_dis                                   -0.222522  \n",
       "fuzzy_ratio                                     0.690133  \n",
       "fuzzy_set_ratio                                 0.516180  \n",
       "fuzzy_partial_ratio                             0.401680  \n",
       "fuzzy_token_sort_ratio                          0.688953  \n",
       "fuzzy_qratio                                    0.687099  \n",
       "fuzzy_WRatio                                    0.325880  \n",
       "longest_substr_ratio                           -0.219458  \n",
       "q1_cómo                                              NaN  \n",
       "q2_cómo                                              NaN  \n",
       "cómo_both                                            NaN  \n",
       "q1_qué                                               NaN  \n",
       "q2_qué                                               NaN  \n",
       "qué_both                                             NaN  \n",
       "simhash_distance                               -0.462483  \n",
       "simhash_distance_2gram                         -0.382584  \n",
       "simhash_distance_3gram                         -0.233500  \n",
       "simhash_distance_ch_2gram                      -0.555032  \n",
       "simhash_distance_ch_3gram                      -0.668282  \n",
       "jellyfish_jaro_winkler_distance                 0.610006  \n",
       "smith_waterman_distance                         1.000000  \n",
       "\n",
       "[53 rows x 53 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[-10000:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract training columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_columns = ['bm25_q1_to_q2', 'bm25_q2_to_q1', 'weighted_cosine_sim',\n",
    "       'len_word_max', 'len_word_min', 'len_char_max', 'len_char_min',\n",
    "       'word_length_diff', 'char_length_diff', 'len_diff_remove_stopwords',\n",
    "       'word_match', 'tfidf_word_match', 'shared_count', 'bigram_corr', 'trigram_corr',\n",
    "       'word_match_no_stopwords', 'unique_word_ratio', 'cosine_sim',\n",
    "       'manhattan_dis', 'eucledian_dis', 'jaccard_dis', 'minkowsk_dis',\n",
    "       'fuzzy_ratio', 'fuzzy_set_ratio', 'fuzzy_partial_ratio',\n",
    "       'fuzzy_token_sort_ratio', 'fuzzy_qratio', 'fuzzy_WRatio',\n",
    "       'longest_substr_ratio', 'cómo_both', 'simhash_distance', 'simhash_distance_2gram',\n",
    "       'simhash_distance_3gram', 'simhash_distance_ch_2gram',\n",
    "       'simhash_distance_ch_3gram', 'raw_wmd', 'word2vec_jaccard_distance',\n",
    "       'freq_based_word2vec_cosine_distance',\n",
    "       'freq_based_word2vec_jaccard_distance',\n",
    "       'lda_balanced_euclidean_distance', 'lsi_cosine_distance',\n",
    "       'lsi_jaccard_distance', 'jellyfish_jaro_winkler_distance',\n",
    "       'smith_waterman_distance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/processed_dataset/engineered_words_test.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(train_output_path, index=False, encoding='utf-8')\n",
    "test_df.to_csv(test_output_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
